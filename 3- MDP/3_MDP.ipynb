{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "3_MDP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcg3cq6SlpxQ"
      },
      "source": [
        "# Frozen Lake 4*4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfNTsU3elpxT"
      },
      "source": [
        "Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend.\n",
        "\n",
        "The surface is described using a grid like the following:\n",
        "\n",
        "SFFF       (S: starting point, safe)\n",
        "\n",
        "FHFH       (F: frozen surface, safe)\n",
        "\n",
        "FFFH       (H: hole, fall to your doom)\n",
        "\n",
        "HFFG       (G: goal, where the frisbee is located)\n",
        "\n",
        "\n",
        "The episode ends when you reach the goal or fall in a hole. You receive a reward of 100 if you reach the goal, -100 if you fall into the hole, and -0.1 for each step you take.\n",
        "\n",
        "\n",
        "[link](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py) of the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fm_e_nnlpxU"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZVGHZnclpxV"
      },
      "source": [
        "Run the following code and observe the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuU_5VGapL2I"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db4Z-whRlpxV"
      },
      "source": [
        "import gym\n",
        " \n",
        "MAX_ITERATIONS = 10\n",
        " \n",
        "env = gym.make(\"FrozenLake-v0\")\n",
        "env.reset()\n",
        "# env.render()\n",
        "for i in range(MAX_ITERATIONS):\n",
        "    random_action = env.action_space.sample()\n",
        "    new_state, reward, done, info = env.step(random_action)\n",
        "\n",
        "    env.render()\n",
        "    \n",
        "    if done:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Q-za2LqrcP"
      },
      "source": [
        "### Code explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaq6uF1MrZ0X"
      },
      "source": [
        "action space in frozen lake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI8fiMtDlpxZ"
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUhqSGEIqmTX"
      },
      "source": [
        "random_action = env.action_space.sample()\n",
        "\n",
        "print(random_action)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkbOHVu8sGXa"
      },
      "source": [
        "observation space in frozen lake"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGtCwbZYqat_"
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwCIbPjzsMYE"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "for _ in range(10):\n",
        "  random_action = env.action_space.sample()\n",
        "  new_state, _, _, _ = env.step(random_action)\n",
        "\n",
        "  print('\\n\\n----------------------------')\n",
        "  print('action : ',random_action)\n",
        "  print('new state : ',new_state)\n",
        "\n",
        "  env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZf1X2vXtoNa"
      },
      "source": [
        "now guess what's the state and action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc0I4EiMqarN"
      },
      "source": [
        "???????????????? 5min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPDAuv8LzGrp"
      },
      "source": [
        "## modify reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3z1A081pBM"
      },
      "source": [
        "set a proper reward function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZiSJKcxzKGh"
      },
      "source": [
        "the problem of reward function\n",
        "\n",
        "solve the problem ????????????????  6-7 min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIRsUZxuyL0h"
      },
      "source": [
        "## find out values for a random policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09UghrRqaFj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.choice?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTzKj-yIqaoz"
      },
      "source": [
        "make a random policy\n",
        "\n",
        "????????????????????????? 5min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaGsEvic6mB"
      },
      "source": [
        "generate values for each state 10 min + 15 min\n",
        "\n",
        "# env.env.s = start_state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FIms-DDgSxI"
      },
      "source": [
        "## make the optimal policy and evaluate that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt5QnMfbgPK1"
      },
      "source": [
        "try to make the optimal policy\n",
        "evaluate that\n",
        "\n",
        "10 min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpvXEiSJhiL4"
      },
      "source": [
        "compare two policies ??????"
      ]
    }
  ]
}